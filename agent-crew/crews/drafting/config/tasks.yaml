draft_response_task:
  description: >
    **먼저, 당신의 도구를 사용해** 학생의 문의에 답하는 데 필요한 '참조 정보'를 검색하세요.
    이메일의 카테고리는 **'{category}'**입니다.
    
    - 카테고리가 'TASK'이면: **`사내 규정 및 FAQ 검색 도구 (RAG)`**을 사용하세요.
    - 카테고리가 'Simple_Inquiry'이면: **`조직도 및 업무 분장표 로드 도구`**를 사용하세요.

    검색된 '참조 정보'를 바탕으로, 아래 학생의 문의에 대한 답변 초안을 작성하세요.

    **[학생 문의 요약]**
    {email_summary}

    **[학생 문의 원문]**
    {email_body}
  expected_output: >
    학생에게 바로 발송할 수 있는 완성된 이메일 답변 초안 (Markdown 형식). 
    (참조한 정보를 답변에 자연스럽게 포함하세요.)
  agent: response_generation_agent

validate_draft_task:
  description: >
    **[당신의 임무]**
    당신은 [CONTEXT]에 주어진 답변 초안을 검증해야 합니다.
    검증을 위해, **반드시** 아래 [작업 1]과 [작업 2]를 순서대로 수행하세요.

    **[작업 1: 사실 확인 (도구 사용)]**
    [CONTEXT]를 평가하기 전, **먼저** '참조 정보(Ground Truth)'를 검색해야 합니다.
    
    **현재 이메일의 카테고리는 '{category}'입니다.**
    
    **[도구 사용 규칙]**
    - 카테고리가 'TASK'이면: **`사내 규정 및 FAQ 검색 도구 (RAG)`**를 호출하세요.
    - 카테고리가 'Simple_Inquiry' 또는 'Directory_Inquiry'이면: **`조직도 및 업무 분장표 로드 도구`**를 호출하세요.

    **[검색 쿼리]**
    - RAG 도구를 사용할 경우: [원본 문의 요약]의 **`{email_summary}`** 텍스트를 `query`로 사용하세요.
    - 조직도 로드 도구를 사용할 경우: 쿼리가 필요 없습니다.
    
    **[원본 문의 요약 (참고용)]**
    {email_summary}

    **[작업 2: 초안 평가]**
    [작업 1]에서 당신이 직접 검색한 '참조 정보'를 기준으로, [CONTEXT]의 답변 초안을 평가하세요.

    **[학생 문의 원문 (참고용)]**
    {email_body}

    **[평가 기준]**
    1. 사실성(Factuality): [CONTEXT]의 초안이 당신이 직접 검색한 '참조 정보'와 100% 일치하는가?
    2. 관련성(Relevance): [CONTEXT]의 초안이 '학생 문의 원문'에 대한 답을 모두 포함하는가?
    3. 어조(Tone): 학교의 공식적이고 친절한 어조를 유지하는가?
  expected_output: >
    평가 결과를 `DraftValidation` Pydantic 모델의 JSON 형식으로 반환합니다.
  agent: draft_validation_agent