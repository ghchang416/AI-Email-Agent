draft_response_task:
  description: >
    **[당신의 임무]**
    학생의 문의에 답하는 데 필요한 '참조 정보'를 검색하고, 답변 초안을 작성하세요.
    
    **[이메일 정보]**
    - 이메일 카테고리: **'{category}'**
    - 학생 문의 요약: **{email_summary}**
    - 학생 문의 원문: {email_body}
    
    **[작업 지침]**
    1.  카테고리가 'Simple_Inquiry'이면: **`조직도 및 업무 분장표 로드 도구`**를 사용하세요.
    2.  카테고리가 'TASK'이면: **반드시 "하이브리드 RAG 검색"**을 수행하세요.
        - **(1단계) 라우팅:** **`사용 가능한 RAG 문서 목록 조회`** 도구를 호출하여 DB에 있는 PDF 파일명 목록을 확인합니다.
        - **(2단계) 메타데이터 추출 및 파일 선택:** '{email_summary}'와 '{email_body}'에서 **'학과', '연도', '주제어' 등 핵심 메타데이터를 추출**합니다. 이 메타데이터를 기반으로 (1단계) 목록에서 가장 적합한 **파일명 1개** (예: '..._소프트웨어학과.pdf')를 선택합니다.
        - **(3단계) 시맨틱 쿼리 생성:** (2단계)의 메타데이터를 제외한, 학생의 **순수한 "의도"**를 나타내는 **시맨틱 검색 쿼리 3개**를 생성합니다. (예: "졸업요건 충족 여부", "전공 심화 과정 이수 방법", "필수 이수 학점 확인")
        - **(4단계) 다중 검색:** **`사내 규정 및 FAQ 검색 도구 (RAG)`**를 위에서 생성한 **3개의 쿼리 각각에 대해 총 3번 호출**합니다. (모두 (2단계)에서 선택한 동일한 `source_file` 사용)
        - **(5단계) 문맥 취합:** (4단계)에서 반환된 **모든 '참조 정보' 텍스트를 하나로 합칩니다.**
    
    **[초안 작성]**
    (5단계)에서 취합된 '참조 정보'를 바탕으로, 학생의 문의에 대한 답변 초안을 작성하세요.
  expected_output: >
    학생에게 바로 발송할 수 있는 완성된 이메일 답변 초안 (Markdown 형식). 
    (참조한 정보를 답변에 자연스럽게 포함하세요.)
  agent: response_generation_agent

validate_draft_task:
  description: >
    **[당신의 임무]**
    당신은 [CONTEXT]에 주어진 답변 초안을 검증해야 합니다.
    
    **[작업 1: 사실 확인 (하이브리드 RAG)]**
    [CONTEXT]를 평가하기 전, **먼저** '참조 정보(Ground Truth)'를 검색해야 합니다.
    
    - **현재 이메일 카테고리:** '{category}'
    - **원본 문의 요약:** {email_summary}

    **[도구 사용 규칙]**
    1.  카테고리가 'Simple_Inquiry' 또는 'Directory_Inquiry'이면: **`조직도 및 업무 분장표 로드 도구`**를 호출하세요.
    2.  카테고리가 'TASK'이면: **반드시 "하이브리드 RAG 검색"**을 수행하세요.
        - **(1단계) 라우팅:** **`사용 가능한 RAG 문서 목록 조회`** 도구를 호출합니다.
        - **(2단계) 메타데이터 추출 및 파일 선택:** '{email_summary}'와 '{email_body}'에서 **'학과', '연도', '주제어' 등 핵심 메타데이터를 추출**합니다. 이 메타데이터를 기반으로 (1단계) 목록에서 가장 적합한 **파일명 1개** (예: '..._소프트웨어학과.pdf')를 선택합니다.
        - **(3단계) 시맨틱 쿼리 생성:** (2단계)의 메타데이터를 제외한, 학생의 **순수한 "의도"**를 나타내는 **시맨틱 검색 쿼리 3개**를 생성합니다. (예: "졸업요건 충족 여부", "전공 심화 과정 이수 방법", "필수 이수 학점 확인")
        - **(4단계) 다중 검색:** **`사내 규정 및 FAQ 검색 도구 (RAG)`**를 위에서 생성한 **3개의 쿼리 각각에 대해 총 3번 호출**합니다. (모두 (2단계)에서 선택한 동일한 `source_file` 사용)
        - **(5단계) 문맥 취합:** 반환된 **모든 '참조 정보'를 하나로 합칩니다.**

    **[작업 2: 초안 평가]**
    [작업 1]에서 당신이 직접 취합한 '참조 정보'를 기준으로, [CONTEXT]의 답변 초안을 평가하세요.
    (학생 문의 원문: {email_body})

    **[평가 기준]**
    1. 사실성(Factuality): [CONTEXT]의 초안이 당신이 직접 검색한 '참조 정보'와 100% 일치하는가?
    2. 관련성(Relevance): [CONTEXT]의 초안이 '학생 문의 원문'에 대한 답을 모두 포함하는가?
    3. 어조(Tone): 학교의 공식적이고 친절한 어조를 유지하는가?
  expected_output: >
    평가 결과를 `DraftValidation` Pydantic 모델의 JSON 형식으로 반환합니다.
  agent: draft_validation_agent